{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex  Age  SibSp  Parch  Embarked  Title\n",
       "0           0       3    0  1.0      1      0         0      0\n",
       "1           1       1    1  1.0      1      0         2      2\n",
       "2           1       3    1  1.0      0      0         0      1\n",
       "3           1       1    1  1.0      1      0         0      2\n",
       "4           0       3    0  1.0      0      0         0      0\n",
       "..        ...     ...  ...  ...    ...    ...       ...    ...\n",
       "886         0       2    0  1.0      0      0         0      0\n",
       "887         1       1    1  0.0      0      0         0      1\n",
       "888         0       3    1  1.0      1      2         0      1\n",
       "889         1       1    0  1.0      0      0         2      0\n",
       "890         0       3    0  1.0      0      0         1      0\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "\n",
    "\n",
    "# data loading (train data set loading)\n",
    "train_df = pd.read_csv(\"./data/titanic/train.csv\")\n",
    "train_df.head()\n",
    "\n",
    "train_df.shape\n",
    "train_df.info()   # 각 column(feature)의 상세정보를 출력\n",
    "# cabin null너무 많아서 유의하지 않을거같아\n",
    "train_df.isnull().sum(axis=0) # 행방향으로 sum\n",
    "# 결측치와 이상치를 찾아서 적절한 값으로 변경하던가\n",
    "# 아니면 삭제하던가 처리를 해야해요\n",
    "\n",
    "# Name은 그 자체로는 크게 의미가 없어보이지만 이름의 특정 keyword가 들어가 있고\n",
    "# 이 keyword가 생존에 영향을 미칠 수 있다\n",
    "# train_df[\"Name\"].str.extract(\"정규식\")\n",
    "train_df[\"Title\"] = train_df[\"Name\"].str.extract(\"([A-Za-z]+)\\.\")\n",
    "# 문자열을 가져와서 추출할건데 패턴이있어 (정규식)\n",
    "# + : 한개 이상\n",
    "# \\ escape시켜서 . 자체를 뽑고 싶어\n",
    "# 새로운 컬럼\n",
    "train_df[\"Title\"].value_counts()\n",
    "\n",
    "\n",
    "# 너무 많아서 4개로만\n",
    "# Title 안에 Mr, Miss, Mrs, other를 각각 0,1,2,3으로 변환\n",
    "title_mapping_dict = {\"Mr\" : 0, \"Miss\" : 1, \"Mrs\" : 2, \"Master\" : 3, \"Dr\" : 3, \"Rev\" : 0,\n",
    "                      \"Mlle\" : 1, \"Major\" : 3,\"Col\" : 3,\"Countess\" : 2,\"Capt\" : 3,\"Sir\" : 3,\"Lady\" : 3,\n",
    "                      \"Jonkheer\" : 0,\"Don\" : 0,\"Mme\" : 2,\"Ms\" : 3}\n",
    "\n",
    "train_df[\"Title\"] = train_df[\"Title\"].map(title_mapping_dict)\n",
    "train_df\n",
    "#stackedBarChart(\"Title\")\n",
    "train_df.drop(\"Name\", axis = 1, inplace=True)   # 원본에서 컬럼을 삭제하겠다\n",
    "train_df.drop(\"Ticket\", axis = 1, inplace=True)\n",
    "train_df.drop(\"Cabin\", axis = 1, inplace=True)\n",
    "train_df\n",
    "\n",
    "sex_mapping_dict = {\"male\" : 0, \"female\" : 1}\n",
    "train_df[\"Sex\"]= train_df[\"Sex\"].map(sex_mapping_dict)\n",
    "train_df\n",
    "\n",
    "# 탑승지역의 결측치를 \"S\"로 대체 (S에서 가장많이 탔어)\n",
    "train_df[\"Embarked\"].fillna(\"S\", inplace=True)\n",
    "# 탑승지역 column에 대해 S => 0, Q => 1. C => 2 로 변환\n",
    "embarked_mapping_dict = {\"S\" : 0, \"Q\" : 1, \"C\" : 2}\n",
    "train_df[\"Embarked\"]= train_df[\"Embarked\"].map(embarked_mapping_dict)\n",
    "train_df\n",
    "\n",
    "# Age에는 결측치가 많아요!\n",
    "# 결측치를 대체해서 채워넣어야해요!\n",
    "# - 전체 사람의 평균을 구해서 결측치를 채워요\n",
    "# - Title을 이용해서 각 title에 맞는 평균 나이로 결측치를 채운다.\n",
    "# 이건 한번 해보세요\n",
    "age_mean = train_df.groupby(\"Title\")[\"Age\"].mean()\n",
    "a = train_df[train_df[\"Title\"]==0][\"Age\"].fillna(age_mean[0])\n",
    "b = train_df[train_df[\"Title\"]==1][\"Age\"].fillna(age_mean[1])\n",
    "c = train_df[train_df[\"Title\"]==2][\"Age\"].fillna(age_mean[2])\n",
    "d = train_df[train_df[\"Title\"]==3][\"Age\"].fillna(age_mean[3])\n",
    "result_series = pd.concat([a,b,c,d])\n",
    "train_df[\"Age\"]=result_series.sort_index()\n",
    "train_df\n",
    "\n",
    "# Age 에 대해서 Binning 처리\n",
    "# Binning처리를 할 때 고려해야 할 사항 => 간격을 어떻게 설정?\n",
    "# Age => 0~20 : 0\n",
    "# Age => 20초과~40이하 : 1\n",
    "# Age => 40초과~60이하 : 2\n",
    "# Age => 60초과 : 3\n",
    "\n",
    "train_df.loc[train_df[\"Age\"] <= 20, \"Age\"] = 0\n",
    "train_df.loc[(train_df[\"Age\"] > 20) & (train_df[\"Age\"] <= 40), \"Age\"] = 1\n",
    "train_df.loc[(train_df[\"Age\"] > 40) & (train_df[\"Age\"] <= 60), \"Age\"] = 2\n",
    "train_df.loc[train_df[\"Age\"] > 60, \"Age\"] = 3\n",
    "# loc[행, 열]\n",
    "\n",
    "\n",
    "train_df\n",
    "\n",
    "\n",
    "# # Fare까지 Binning처리를 해보아요\n",
    "# # 모든 전처리가 끝나게 되요!\n",
    "# plt.boxplot(train_df[\"Fare\"])\n",
    "# q1,q2,q3 = np.percentile(train_df[\"Fare\"],[25,50,75])\n",
    "# print(q1,q2,q3)\n",
    "\n",
    "# q1,q2,q3 = np.percentile(train_df[\"Fare\"],[25,50,75])\n",
    "# print(q1,q2,q3)\n",
    "\n",
    "# train_df.loc[train_df[\"Fare\"] <= 7.8958, \"Fare\"] = 0\n",
    "# train_df.loc[(train_df[\"Fare\"] > 7.8958) & (train_df[\"Fare\"] <= 14.4542), \"Fare\"] = 1\n",
    "# train_df.loc[(train_df[\"Fare\"] > 14.4542) & (train_df[\"Fare\"] <=  31.5), \"Fare\"] = 2\n",
    "# train_df.loc[train_df[\"Fare\"] >  31.5, \"Fare\"] = 3\n",
    "\n",
    "train_df.drop(\"PassengerId\",axis=1, inplace=True)\n",
    "train_df.drop(\"Fare\",axis=1, inplace=True)\n",
    "train_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num = int(train_df.shape[0] * 0.8)    #712\n",
    "train_num\n",
    "test_num = train_df.shape[0] - train_num\n",
    "\n",
    "# train data set\n",
    "# 원래는 이렇게 시작: x_data = \n",
    "train_x_data = train_df.drop(\"Survived\",axis=1, inplace = False)[:train_num].values\n",
    "test_x_data = train_df.drop(\"Survived\",axis=1, inplace = False)[train_num:].values\n",
    "\n",
    "\n",
    "train_y_data  = train_df[\"Survived\"][:train_num].values.reshape([-1,1])\n",
    "test_y_data  = train_df[\"Survived\"][train_num:].values.reshape([-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost값은 : 1.8309122323989868\n",
      "Cost값은 : 0.7910777926445007\n",
      "Cost값은 : 0.7141587734222412\n",
      "Cost값은 : 0.7103261351585388\n",
      "Cost값은 : 0.6708146929740906\n",
      "Cost값은 : 0.5694059133529663\n",
      "Cost값은 : 0.5658324360847473\n",
      "Cost값은 : 0.5438045263290405\n",
      "Cost값은 : 0.5077757835388184\n",
      "Cost값은 : 0.48563000559806824\n",
      "정확도:0.8770949840545654\n"
     ]
    }
   ],
   "source": [
    "# 그래프 초기화\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape = [None,7], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape = [None,1], dtype=tf.float32)\n",
    "dout_rate = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "# Weight & bias(Deep & Wide)\n",
    "W1 = tf.get_variable(\"weight1\", shape=[7,256],\n",
    "                    initializer = tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]), name=\"bias1\")\n",
    "# depth가 이깊으로면깊을수록 연상이 안돼\n",
    "_layer1 = tf.nn.relu(tf.matmul(X,W1)+b1)\n",
    "layer1 = tf.nn.dropout(_layer1, keep_prob=dout_rate)\n",
    " \n",
    "W2 = tf.get_variable(\"weight2\", shape=[256,256],\n",
    "                    initializer = tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([256]), name=\"bias2\")\n",
    "_layer2 = tf.nn.relu(tf.matmul(layer1,W2)+b2)\n",
    "layer2 = tf.nn.dropout(_layer2, keep_prob=dout_rate) \n",
    " \n",
    "W3 = tf.get_variable(\"weight3\", shape=[256,1],\n",
    "                    initializer = tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([1]), name=\"bias3\")\n",
    "\n",
    "\n",
    "# Hypothesis\n",
    "logit= tf.matmul(layer2,W3) + b3\n",
    "H = tf.nn.relu(logit)\n",
    "\n",
    "# cost\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit, labels=Y)) \n",
    "\n",
    "# train\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.00001).minimize(cost)   \n",
    "\n",
    "# session chrlghk\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "# num_of_epoch = 500   #반복횟수\n",
    "# batch_size = 100\n",
    "\n",
    "# for step in range(num_of_epoch):\n",
    "#     num_of_iter = int(train_num/batch_size)\n",
    "#     cost_val=0\n",
    "                      \n",
    "#     for i in range(num_of_iter):\n",
    "#         batch_x=train_x_data[i*batch_size:(i+1)*batch_size]\n",
    "#         batch_y=train_y_data[i*batch_size:(i+1)*batch_size]\n",
    "#         _,cost_val = sess.run([train,cost],\n",
    "#                              feed_dict={X:batch_x,\n",
    "#                                         Y:batch_y})\n",
    "#     if step%5 ==0:\n",
    "#         print(\"cost:{}\".format(cost_val))\n",
    "\n",
    "\n",
    "for step in range(3000): #  코스트값을 3000번 줄이겠다 는 뜻\n",
    "    _, cost_val=sess.run([train, cost], feed_dict = {X : train_x_data,\n",
    "                                                     Y : train_y_data,\n",
    "                                                     dout_rate:0.7} ) # 먹이를 줘야지 그데이터가지고 학습해 \n",
    "    if step % 300 == 0:\n",
    "        print(\"Cost값은 : {}\".format(cost_val))\n",
    "        \n",
    "predict = tf.cast(H > 0.5, dtype = tf.float32)\n",
    "# 예측값\n",
    "# 1에 가까울 확률이 나오게 됨\n",
    "# 기준점 잡아줘야해 얼마가 나올거냐\n",
    "# t,f 놓은 이유 -> 0과 1 둘중의 하나의 값으로 변환시켜주기위해\n",
    "# 예측값과 실제 값과 비교를위해\n",
    "# predict = tf.equal(predict, Y)\n",
    "correct = tf.equal(predict, Y)\n",
    "# 같니?\n",
    "# t/f\n",
    "accuracy = tf.reduce_mean(tf.cast(correct,dtype=tf.float32)) # 0101가지고 평균 몇퍼센트냐\n",
    "print(\"정확도:{}\". format(sess.run(accuracy,\n",
    "                                feed_dict = {X : test_x_data,\n",
    "                                             Y : test_y_data,\n",
    "                                             dout_rate:1})))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test로 해보자~!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# data loading (train data set loading)\n",
    "test_df = pd.read_csv(\"./data/titanic/test.csv\")\n",
    "test_df.head()\n",
    "\n",
    "# Name은 그 자체로는 크게 의미가 없어보이지만 이름의 특정 keyword가 들어가 있고\n",
    "# 이 keyword가 생존에 영향을 미칠 수 있다\n",
    "# train_df[\"Name\"].str.extract(\"정규식\")\n",
    "test_df[\"Title\"] = test_df[\"Name\"].str.extract(\"([A-Za-z]+)\\.\")\n",
    "# 문자열을 가져와서 추출할건데 패턴이있어 (정규식)\n",
    "# + : 한개 이상\n",
    "# \\ escape시켜서 . 자체를 뽑고 싶어\n",
    "# 새로운 컬럼\n",
    "test_df[\"Title\"].value_counts()\n",
    "\n",
    "# 너무 많아서 4개로만\n",
    "# Title 안에 Mr, Miss, Mrs, other를 각각 0,1,2,3으로 변환\n",
    "title_mapping_dict = {\"Mr\" : 0, \"Miss\" : 1, \"Mrs\" : 2, \"Master\" : 3, \"Dr\" : 3, \"Rev\" : 0,\n",
    "                      \"Mlle\" : 1, \"Major\" : 3,\"Col\" : 3,\"Countess\" : 2,\"Capt\" : 3,\"Sir\" : 3,\"Lady\" : 3,\n",
    "                      \"Jonkheer\" : 0,\"Dona\" : 2,\"Mme\" : 2,\"Ms\" : 3}\n",
    "\n",
    "test_df[\"Title\"] = test_df[\"Title\"].map(title_mapping_dict)\n",
    "test_df\n",
    "#stackedBarChart(\"Title\")\n",
    "test_df.drop(\"Name\", axis = 1, inplace=True)   # 원본에서 컬럼을 삭제하겠다\n",
    "test_df.drop(\"Ticket\", axis = 1, inplace=True)\n",
    "test_df.drop(\"Cabin\", axis = 1, inplace=True)\n",
    "test_df\n",
    "\n",
    "# 성별 column에 대해 male => 0, female => 1 로 변환\n",
    "sex_mapping_dict = {\"male\" : 0, \"female\" : 1}\n",
    "test_df[\"Sex\"]= test_df[\"Sex\"].map(sex_mapping_dict)\n",
    "test_df\n",
    "\n",
    "# 탑승지역의 결측치를 \"S\"로 대체 (S에서 가장많이 탔어)\n",
    "test_df[\"Embarked\"].fillna(\"S\", inplace=True)\n",
    "# 탑승지역 column에 대해 S => 0, Q => 1. C => 2 로 변환\n",
    "embarked_mapping_dict = {\"S\" : 0, \"Q\" : 1, \"C\" : 2}\n",
    "test_df[\"Embarked\"]= test_df[\"Embarked\"].map(embarked_mapping_dict)\n",
    "test_df\n",
    "\n",
    "# Age에는 결측치가 많아요!\n",
    "# 결측치를 대체해서 채워넣어야해요!\n",
    "# - 전체 사람의 평균을 구해서 결측치를 채워요\n",
    "# - Title을 이용해서 각 title에 맞는 평균 나이로 결측치를 채운다.\n",
    "# 이건 한번 해보세요\n",
    "age_mean = test_df.groupby(\"Title\")[\"Age\"].mean()\n",
    "a = test_df[test_df[\"Title\"]==0][\"Age\"].fillna(age_mean[0])\n",
    "b = test_df[test_df[\"Title\"]==1][\"Age\"].fillna(age_mean[1])\n",
    "c = test_df[test_df[\"Title\"]==2][\"Age\"].fillna(age_mean[2])\n",
    "d = test_df[test_df[\"Title\"]==3][\"Age\"].fillna(age_mean[3])\n",
    "result_series = pd.concat([a,b,c,d])\n",
    "test_df[\"Age\"]=result_series.sort_index()\n",
    "test_df\n",
    "\n",
    "# Age 에 대해서 Binning 처리\n",
    "# Binning처리를 할 때 고려해야 할 사항 => 간격을 어떻게 설정?\n",
    "# Age => 0~20 : 0\n",
    "# Age => 20초과~40이하 : 1\n",
    "# Age => 40초과~60이하 : 2\n",
    "# Age => 60초과 : 3\n",
    "\n",
    "test_df.loc[test_df[\"Age\"] <= 20, \"Age\"] = 0\n",
    "test_df.loc[(test_df[\"Age\"] > 20) & (test_df[\"Age\"] <= 40), \"Age\"] = 1\n",
    "test_df.loc[(test_df[\"Age\"] > 40) & (test_df[\"Age\"] <= 60), \"Age\"] = 2\n",
    "test_df.loc[test_df[\"Age\"] > 60, \"Age\"] = 3\n",
    "# loc[행, 열]\n",
    "\n",
    "\n",
    "test_df\n",
    "\n",
    "#test_df.dropna(inplace=True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# test_df[\"Fare\"].fillna(test_df[\"Fare\"].mean(),inplace=True)\n",
    "# q1,q2,q3 = np.percentile(test_df[\"Fare\"],[25,50,75])\n",
    "# print(q1,q2,q3)\n",
    "# test_df.isnull().sum(axis=0)\n",
    "\n",
    "# plt.boxplot(test_df[\"Fare\"])\n",
    "\n",
    "# train_df.loc[train_df[\"Fare\"] <= 7.8958, \"Fare\"] = 0\n",
    "# train_df.loc[(train_df[\"Fare\"] > 7.8958) & (train_df[\"Fare\"] <= 14.4542), \"Fare\"] = 1\n",
    "# train_df.loc[(train_df[\"Fare\"] > 14.4542) & (train_df[\"Fare\"] <=  31.5), \"Fare\"] = 2\n",
    "# train_df.loc[train_df[\"Fare\"] >  31.5, \"Fare\"] = 3\n",
    "\n",
    "\n",
    "\n",
    "# test_df.loc[test_df[\"Fare\"] <= 100, \"Fare\"] = 0\n",
    "# test_df.loc[(test_df[\"Fare\"] > 100) & (test_df[\"Fare\"] <= 200), \"Fare\"] = 1\n",
    "# test_df.loc[(test_df[\"Fare\"] > 200) & (test_df[\"Fare\"] <= 300), \"Fare\"] = 2\n",
    "# test_df.loc[train_df[\"Fare\"] > 300, \"Fare\"] = 3\n",
    "\n",
    "#test_df.drop(\"PassengerId\",axis=1, inplace=True)\n",
    "\n",
    "# 7.9104 14.4542 31.0\n",
    "\n",
    "passengerid=test_df['PassengerId']\n",
    "\n",
    "test_df.drop(\"PassengerId\",axis=1, inplace=True)\n",
    "test_df.drop(\"Fare\",axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost값은 : 0.7805983424186707\n",
      "Cost값은 : 0.6998624801635742\n",
      "Cost값은 : 0.6125634908676147\n",
      "Cost값은 : 0.5648993849754333\n",
      "Cost값은 : 0.5432078838348389\n",
      "Cost값은 : 0.5029274225234985\n",
      "Cost값은 : 0.4840856194496155\n",
      "Cost값은 : 0.46741345524787903\n",
      "Cost값은 : 0.48935696482658386\n",
      "Cost값은 : 0.4561585783958435\n",
      "정확도:0.8826815485954285\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# 그래프 초기화\n",
    "tf.reset_default_graph()\n",
    "# data set을 준비해야 한다\n",
    "# 정확도를 측정하기 위해서 학습용 데이터와 평가용 데이터를 따로 분리해야 한다\n",
    "# train_df를 살짝 분리해서 학습용 데이터와 평가용 데이터를 생성\n",
    "\n",
    "# 학습용 8 평가용 2  / 평가용 8 평가용 2\n",
    "# 데이터의 편중이 발생할 수 있어\n",
    "\n",
    "# 편향이 발생할 수 있으니 (n fold cross validatation) 교차 검증\n",
    "# 10개로 쪼갠다음 9를 학습 1을 평가\n",
    "# 첫번째는 맨밑에 것이 평가데이터\n",
    "# 두번째는 밑에서 두번째가 평가데이터\n",
    "# 세번째는 밑에서 두번째가 평가데이터\n",
    "# ,,,,\n",
    "\n",
    "# 우리는 8:2 하자\n",
    "# 위에서 80%를 학습용데이터로 하위 20%를 평가용 데이터로 사용\n",
    "\n",
    "\n",
    "# train data set\n",
    "# 원래는 이렇게 시작: x_data = \n",
    "train_x_data = train_df.drop(\"Survived\",axis=1, inplace = False).values\n",
    "train_y_data  = train_df[\"Survived\"].values.reshape([-1,1])\n",
    "\n",
    "\n",
    "# tensorflow를 이용한 logistic regression code가 나오면 된다\n",
    "# placeholder : 입력데이터를 받아들이는 입력 파라메타\n",
    "X = tf.placeholder(shape = [None, 7], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape = [None, 1], dtype=tf.float32)\n",
    "dout_rate = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "\n",
    "# Weight & bias(Deep & Wide)\n",
    "W1 = tf.get_variable(\"weight1\", shape=[7,256],\n",
    "                    initializer = tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]), name=\"bias1\")\n",
    "# depth가 이깊으로면깊을수록 연상이 안돼\n",
    "_layer1 = tf.nn.relu(tf.matmul(X,W1)+b1)\n",
    "layer1 = tf.nn.dropout(_layer1, keep_prob=dout_rate)\n",
    "\n",
    "\n",
    "W2 = tf.get_variable(\"weight2\", shape=[256,256],\n",
    "                    initializer = tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([256]), name=\"bias2\")\n",
    "_layer2 = tf.nn.relu(tf.matmul(layer1,W2)+b2)\n",
    "layer2 = tf.nn.dropout(_layer2, keep_prob=dout_rate) \n",
    " \n",
    "W3 = tf.get_variable(\"weight3\", shape=[256,1],\n",
    "                    initializer = tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([1]), name=\"bias3\")\n",
    "\n",
    "\n",
    "# Hypothesis\n",
    "logit= tf.matmul(layer2,W3) + b3\n",
    "H = tf.nn.relu(logit)\n",
    "\n",
    "# cost\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit, labels=Y)) \n",
    "\n",
    "# train\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.00001).minimize(cost)   \n",
    "\n",
    "\n",
    "# session, 초기화\n",
    "# runner가 필요해 , 초기화 작업 진행되야해\n",
    "sess= tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# nodes드륻었더니 학습 ㄱㄱ\n",
    "for step in range(3000): #  코스트값을 3000번 줄이겠다 는 뜻\n",
    "    _, cost_val=sess.run([train, cost], feed_dict = {X : train_x_data,\n",
    "                                                     Y : train_y_data,\n",
    "                                                     dout_rate : 0.7} ) # 먹이를 줘야지 그데이터가지고 학습해 \n",
    "    if step % 300 == 0:\n",
    "        print(\"Cost값은 : {}\".format(cost_val))\n",
    "        \n",
    "# 우리가 원하는 W와 b를 구했다! => 모델을 구성했다\n",
    "# 정확도를 측정\n",
    "# 테스트용 x 입력데이터(test_x_data)를 넣어서 예측을 해요!\n",
    "# 이렇게 구한 예측값과 y입력데이터(test_y_data)를 비교해요\n",
    "# 예측값과 실제데이터의 차이를 비율로 계산해보자\n",
    "\n",
    "predict = tf.cast(H > 0.5, dtype = tf.float32)\n",
    "# 예측값\n",
    "# 1에 가까울 확률이 나오게 됨\n",
    "# 기준점 잡아줘야해 얼마가 나올거냐\n",
    "# t,f 놓은 이유 -> 0과 1 둘중의 하나의 값으로 변환시켜주기위해\n",
    "# 예측값과 실제 값과 비교를위해\n",
    "# predict = tf.equal(predict, Y)\n",
    "correct = tf.equal(predict, Y)\n",
    "# 같니?\n",
    "# t/f\n",
    "accuracy = tf.reduce_mean(tf.cast(correct,dtype=tf.float32)) # 0101가지고 평균 몇퍼센트냐\n",
    "print(\"정확도:{}\". format(sess.run(accuracy,\n",
    "                                feed_dict = {X : test_x_data,\n",
    "                                             Y : test_y_data,\n",
    "                                             dout_rate:1})))\n",
    "\n",
    "# 학습 끝났어\n",
    "# kaggle에서 제공한 test.csv파일이 있어요!\n",
    "# test.csv를 이용해서 prediction을 해야해요\n",
    "# 예측결과가 나와요! => 파일로 만들어서 제출\n",
    "\n",
    "# test.csv를 살펴보면 train.csv와 같아요\n",
    "# 결측치처리 ...똑같이 처리해야해\n",
    "# test.csv도 accuracy를 구할 수 있는 형태로 feature enginneering을 해야해\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         1\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_data = test_df.values\n",
    "H_result = sess.run(H, feed_dict={X:x_data,\n",
    "                                  dout_rate:1})\n",
    "predict = tf.cast(H_result > 0.5, dtype = tf.int32)\n",
    "result = sess.run(predict)\n",
    "\n",
    "datafm=pd.DataFrame(result, columns=['Survived']) \n",
    "datafm\n",
    "#t_df = pd.read_csv(\"./data/titanic/test.csv\")\n",
    "#pid=t_df[\"PassengerId\"]\n",
    "\n",
    "Pid=pd.DataFrame(passengerid, columns=[\"PassengerId\"])\n",
    "Pid\n",
    "\n",
    "dd=pd.concat([Pid,datafm], axis=1)\n",
    "dd\n",
    "dd.to_csv(\"gender_submission_1.csv\",index=False)\n",
    "display(dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 80% 넘김~!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[CPU_ENV]",
   "language": "python",
   "name": "cpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
