{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 1.4 0.2]\n",
      " [4.9 1.4 0.2]\n",
      " [4.7 1.3 0.2]]\n",
      "[0.68112222 0.18871289 3.09550267 0.57713289]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "iris = datasets.load_iris() #데이터를 로드\n",
    "\n",
    "features = iris.data # 특성과 타깃을 만듭니다\n",
    "target = iris.target\n",
    "\n",
    "thresholder = VarianceThreshold(threshold=.5) # 기준값을 만듭니다\n",
    "\n",
    "features_high_variance = thresholder.fit_transform(features) # 기준값보다 높은 특성을 선택합니다.\n",
    "\n",
    "print(features_high_variance[0:3]) # 선택한 특성을 확인\n",
    "print(thresholder.variances_) # 분산 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler() # 특성 행렬을 표준화합니다.\n",
    "features_std = scaler.fit_transform(features)\n",
    "\n",
    "selector = VarianceThreshold() # 각 특성의 분산을 계산합니다.\n",
    "selector.fit(features_std).variances_\n",
    "# 표준화하면 분산은 열단위로 1이 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      "[0.16 0.16 0.24]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.16, 0.16, 0.24])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "features = [[0, 1, 0], # 예제 특성 행렬\n",
    "\t\t[0, 1, 1], # 특성 0: 80%가 클래스 0\n",
    "\t\t[0, 1, 0], # 특성 1: 80%가 클래스 1\n",
    "\t\t[0, 1, 1], # 특성 2: 60%가 클래스 0, 40%는 클래스 1\n",
    "\t\t[1, 0, 0]]\n",
    "\n",
    "# 분산을 기준으로 선택합니다.\n",
    "thresholder = VarianceThreshold(threshold=(.75 * (1 - .75)))\n",
    "print(thresholder.fit_transform(features))\n",
    "print(thresholder.variances_)\n",
    "\n",
    "import numpy as np\n",
    "np.var(features, axis=0) #넘파이 var 함수를 사용하여 분산을 계산합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 상관관계가 큰 두 개의 특성을 가진 특성 행렬을 만듭니다.\n",
    "features = np.array([[1, 1, 1], [2, 2, 0], [3, 3, 1], [4, 4, 0], [5, 5, 1],\n",
    "\t\t[6, 6, 0], [7, 7, 1], [8, 7, 0], [9, 7, 1]])\n",
    "\n",
    "dataframe = pd.DataFrame(features) # 특성 행렬을 DataFrame으로 변환\n",
    "corr_matrix = dataframe.corr().abs() # 상관관계 행렬을 만듭니다.\n",
    "# 상관관계 행렬의 상삼각(upper triangle) 행렬을 선택합니다.\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "# 상관 계수가 0.95보다 큰 특성 열의 인덱스를 찾습니다.\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2\n",
      "0  1.000000  0.976103  0.000000\n",
      "1  0.976103  1.000000 -0.034503\n",
      "2  0.000000 -0.034503  1.000000\n",
      "    0         1         2\n",
      "0 NaN  0.976103  0.000000\n",
      "1 NaN       NaN  0.034503\n",
      "2 NaN       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "dataframe.drop(dataframe.columns[to_drop], axis=1).head(3) # 특성을 삭제합니다.\n",
    "\n",
    "print(dataframe.corr()) #상관관계 행렬\n",
    "print(upper) #상관관계 행렬의 상삼각 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.97610336  0.        ]\n",
      " [ 0.97610336  1.         -0.03450328]\n",
      " [ 0.         -0.03450328  1.        ]]\n",
      "[[0. 0. 1. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]\n",
      " [1. 1. 0. 0.]\n",
      " [1. 1. 1. 0.]\n",
      " [1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#상관관계 행렬은 넘파이 corrcoef()로 구할 수 있습니다.\n",
    "#corrcoef()는 특성이 행에 놓여 있을 것으로 가정합니다.\n",
    "#특성이 열에 놓여 있다고 알려주려면 rowvar 매개변수를 False로 지정합니다.\n",
    "print(np.corrcoef(features, rowvar=False))\n",
    "\n",
    "# np.triu()는 주어진 배열에서 상삼각 행렬을 추출하여 반환합니다.\n",
    "# 매개변수 k가 기본값 0이면 반환되는 행렬에 대각원소가 포함됩니다.\n",
    "# k값이 커질수록 대각원소에서 k만큼 떨어진 삼각행렬을 반환합니다.\n",
    "# 예) k=2일 경우 주대각선에서 2만큼 떨어진 원소부터 포함됩니다.\n",
    "print(np.triu(np.ones((4, 4)), k=2))\n",
    "\n",
    "# np.tril()는 주어진 배열에서 하삼각 행렬을 추출 반환합니다.\n",
    "print(np.tril(np.ones((4, 4)), k=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 특성 개수: 4\n",
      "줄어든 특성 개수: 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif\n",
    "\n",
    "iris = load_iris() # 데이터 로드\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "features = features.astype(int) # 범주형 데이터를 정수형으로 변환\n",
    "\n",
    "chi2_selector = SelectKBest(chi2, k=2) # 카이제곱 통계값이 가장 큰 특성 두 개를 선택\n",
    "features_kbest = chi2_selector.fit_transform(features, target)\n",
    "\n",
    "print(\"원본 특성 개수:\", features.shape[1]) # 결과 확인\n",
    "print(\"줄어든 특성 개수:\", features_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 특성 개수: 4\n",
      "줄어든 특성 개수: 2\n"
     ]
    }
   ],
   "source": [
    "# F-값이 가장 높은 특성 두 개를 선택합니다.\n",
    "fvalue_selector = SelectKBest(f_classif, k=2)\n",
    "features_kbest = fvalue_selector.fit_transform(features, target)\n",
    "\n",
    "print(\"원본 특성 개수:\", features.shape[1]) # 결과 확인\n",
    "print(\"줄어든 특성 개수:\", features_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 특성 개수: 4\n",
      "줄어든 특성 개수: 3\n"
     ]
    }
   ],
   "source": [
    "# 특정 특성 개수를 선택하는 대신 Selectpercentile를 사용하여 특성의 상위 n 퍼센트를 선택할 수 있습니다.\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "# 가장 큰 F-값의 상위 75% 특성을 선택합니다.\n",
    "fvalue_selector = SelectPercentile(f_classif, percentile=75)\n",
    "features_kbest = fvalue_selector.fit_transform(features, target)\n",
    "\n",
    "print(\"원본 특성 개수:\", features.shape[1]) # 결과 선택\n",
    "print(\"줄어든 특성 개수:\", features_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[230, 152,  50,   0],\n",
       "       [274, 116, 191,  50],\n",
       "       [304, 129, 255,  79]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target\n",
    "#특성 행렬의 차원을 (3, 50, 4)로 바꾸어 클래스별 합을 구합니다.\n",
    "observed = np.sum(features.reshape(3, 50, 4), axis=1)\n",
    "observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([269.33333333, 132.33333333, 165.33333333,  43.        ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#특성 타깃과 전혀 관계없다면 기대 빈도는 전체 합을 클래스 개수 3으로 나눈 값이 됩니다.\n",
    "expected = features.sum(axis=0) / 3\n",
    "expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10.28712871,   5.02267003, 133.06854839,  74.27906977])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#카이제곱 공식에 위헤서 구한 observed와 expected를 대입합니다.\n",
    "np.sum((observed - expected)**2 / expected, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10.28712871,   5.02267003, 133.06854839,  74.27906977])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#카이제곱 값이 큰 세 번째, 네 번째 특성이 선택됩니다. chi2_selector객체의 scores_속성에 저장\n",
    "chi2_selector.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.38666667 2.64666667 3.30666667 0.86      ]\n",
      "[[4.6  3.04 1.   0.  ]\n",
      " [5.48 2.32 3.82 1.  ]\n",
      " [6.08 2.58 5.1  1.58]]\n"
     ]
    }
   ],
   "source": [
    "#ANOVA 직접 계산\n",
    "##전체 평균과 클래스 평균을 계산\n",
    "total_mean = np.mean(features, axis=0)\n",
    "print(total_mean)\n",
    "class_mean = np.mean(features.reshape(3, 50, 4), axis=1)\n",
    "print(class_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 55.41333333  13.29333333 440.01333333  63.88      ]\n",
      "[105.57333333  42.27333333 467.89333333  76.06      ]\n"
     ]
    }
   ],
   "source": [
    "#ss_total 계산\n",
    "ss_between = np.sum(50 * (class_mean - total_mean)**2, axis=0)\n",
    "print(ss_between)\n",
    "ss_total = np.sum((features - total_mean)**2, axis=0)\n",
    "print(ss_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  81.19776715,   33.71497585, 1160.00645624,  385.48275862])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ss_beteen과 ss_tatal을 F-값 공식에 대입\n",
    "f = (ss_between/(3-1)) / ((ss_total-ss_between)/(150-3))\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  81.19715 ,   33.715004, 1160.0116  ,  385.483   ], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fvalue_selector.scores_ #F-값 scores_속성에서 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFECV(cv=None,\n",
      "      estimator=LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
      "                                 normalize=False),\n",
      "      min_features_to_select=1, n_jobs=None, scoring='neg_mean_squared_error',\n",
      "      step=1, verbose=0)\n",
      "[[ 0.00850799  0.7031277  -0.925066  ]\n",
      " [-1.07500204  2.56148527  0.4746258 ]\n",
      " [ 1.37940721 -1.77039484 -0.39616889]\n",
      " ...\n",
      " [-0.80331656 -1.60648007  0.25068305]\n",
      " [ 0.39508844 -1.34564911 -1.35054293]\n",
      " [-0.55383035  0.82880112  0.14050409]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn import datasets, linear_model\n",
    "\n",
    "# 특성 행렬과 타깃 벡터를 생성합니다.\n",
    "# 선형회귀분석에 필요한 모의 데이터 생성\n",
    "features, target = make_regression(n_samples = 10000,  \n",
    "                                n_features = 100,\n",
    "                                n_informative = 2,\n",
    "                                random_state = 1)\n",
    "\n",
    "# 선형 회귀 모델을 만듭니다.\n",
    "ols = linear_model.LinearRegression() \n",
    "\n",
    "# 재귀적으로 특성을 제거합니다.\n",
    "rfecv = RFECV(estimator=ols, step=1, scoring=\"neg_mean_squared_error\")  # neg_mean_squared_error : 평균제곱오차\n",
    "print(rfecv.fit(features, target))\n",
    "print(rfecv.transform(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[False False False False False  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False]\n",
      "[69 15 94 45 13  1 35  6 31 81 36 25  2  7 53 40 27 46 75 65 61 68 92  9\n",
      " 39 48 98 96 47 71 19 37 11 20 50  4 33 42 67  1 43 63 85 86 56 60  5 16\n",
      "  8 55 93 73 10 76  1 77 52 24 58 62 21 82 72 90 80 91 18 30 57 89 64 51\n",
      " 59 17 28 32 49 66 87 84 38 88 34 44 14 79 41 12 29 23  3 78 22 95 26 70\n",
      " 54 83 74 97]\n"
     ]
    }
   ],
   "source": [
    "print(rfecv.n_features_) # 최선의 특성 개수\n",
    "print(rfecv.support_) # 선택된 특성이 표시된 불리언 마스크\n",
    "print(rfecv.ranking_) # 특성의 순위: 최고(1)에서 최악(96)까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFE(estimator=LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
      "                               normalize=False),\n",
      "    n_features_to_select=3, step=1, verbose=0)\n",
      "[[ 0.00850799  0.7031277  -0.925066  ]\n",
      " [-1.07500204  2.56148527  0.4746258 ]\n",
      " [ 1.37940721 -1.77039484 -0.39616889]\n",
      " ...\n",
      " [-0.80331656 -1.60648007  0.25068305]\n",
      " [ 0.39508844 -1.34564911 -1.35054293]\n",
      " [-0.55383035  0.82880112  0.14050409]]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "rfe = RFE(estimator=ols, n_features_to_select=3)\n",
    "print(rfe.fit(features, target))\n",
    "print(rfe.transform(features))\n",
    "# rfe객체가 선택한 특성이 rfecv 객체가 선택한 특성과 동일한지 확인하기 위해 불리언 마스크를 비교\n",
    "print(np.all(rfe.support_ == rfecv.support_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[CPU_ENV]",
   "language": "python",
   "name": "cpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
