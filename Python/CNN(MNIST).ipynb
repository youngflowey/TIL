{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0114\n",
    "\n",
    "# CNN ( Convolutional Neural Network ) : 합성곱 신경망\n",
    "\n",
    "### FC Layer (Fully Connected Layer)\n",
    "- 이전 layer의 모든 node가 다음 layer의 모든 node에 연결되어서 학습되는 구조\n",
    "- FC Layer를 다른말로 Dense Layer라고도 한다!\n",
    "\n",
    "\n",
    "- 지금까지 우리가 작업한 신경망은 모두 FC layer를 이용하고 있다\n",
    "\n",
    "\n",
    "- FC Layer의 특징은 MNIST의 예제처럼 입력데이터가 1차원으로 한정되요!\n",
    "    - 하나의 데이터가 1차원으로   \n",
    "    - 원래 3차원인데 MNIST는 흑백이므로 2차원  \n",
    "    - 2차원이라 FC Layer 이용못했어 그래서 28*28 곱해서 사용  \n",
    "      ===> 즉, 각각의 이미지가 1차원으로 표현이 되어야 한다  \n",
    "  그래서 2차원 이미지를 우리가 1차원으로 변환시켜서 사용한 것  \n",
    "- 우리가 사용한 MNIST예제는 상당히 간단한 이미지 학습, 예측 예제\n",
    "\n",
    "\n",
    "- 이미지 학습의 가장 큰 문제는 이미지가 살짝 휘어있거나 크기가 제각각이거나 변형이 조금만 생겨도 학습이 힘들어 진다\n",
    "- 이런 경우에는 training data가 굉장히 많이 필요하고 추가적으로 학습할 때 많은 시간을 요구하게 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 고민고민고민 하면서 방법을 연구하기 시작\n",
    "\n",
    "\n",
    "- 사람이 학습하는 방식을 모델링\n",
    "    - 하나하나 기억하지 않고, 각사람에 대해서 눈이 크네? 턱이 각져있네 등등 특징을 뽑아서 기억해\n",
    "    - 사람은 변형이 생겨도 그 특징들을 기억해서 판단할 수 있음\n",
    "        - => 데이터가 가지고 있는 특징들을 뽑아내서 일부분을 추출\n",
    "        - => 각각의 특징들을 추출한다고 보면 됨\n",
    "        - => 특징을 뽑아내서 여러개의 이미지를 학습\n",
    "- 하나의 이미지의 특징을 뽑아내서 한이미지를 여러번 학습시킴\n",
    "- 특징을 뽑아서 사이즈를 줄인다음 여러번 학습\n",
    "\n",
    "\n",
    "- 찾아낸 방법은 이미지의 픽셀값을 그대로 입력하는게 아니라 이 이미지를 대표하는 특징을 도출해서 신경망에 여러개 넣어서 학습하는 방식!\n",
    "\n",
    "\n",
    "- 1장의 컬러사진은 width, height, color(depth) 3차원으로 표현\n",
    "- 여러장의 사진이 사용되기 때문에 입력데이터는 4차원으로 표현\n",
    "\n",
    "\n",
    "- 실제 이미지 1장은 3차원이고 이놈을 flatten시켜서 1차원으로 표현해야한다! 크기를 조절해야 되기 때문에 공간에 대한 데이터를 유실할 우려가 있어!\n",
    "- 이런  데이터 유실 때문에 학습과 예측에 문제가 발생하게 된다!\n",
    "- FC Layer에 넣기 전에 \n",
    "- 입력데이터 -> CNN -> 1장의 이미지를 여러개의 이미지로 분할(원본이미지의 특색을 가지고 있는 작은 이미지)[Convolution] -> FC Layer\n",
    "\n",
    "- 공간데이터의 유실을 없애고 이미지의 특성을 추출해서 학습이 용이하게 만드는 방식 => **CNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code로 알아보자\n",
    "사용되어지는 함수부터 알아보자  \n",
    "Sample CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image의 shape : (1, 3, 3, 1)\n",
      "weight의 shape : (2, 2, 1, 3)\n",
      "conv2d의 shape : (1, 2, 2, 3)\n",
      "pool의 shape:(1, 2, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 입력 데이터의 형식 : 3*3*1 이미지 1개를 이용\n",
    "# 입력 데이터 => (이미지개수. width, height, color) => (1,3,3,1)\n",
    "# 총 9개의 데이터가 사용(1~9)\n",
    "image = np.array([[[[1],[2],[3]],\n",
    "                   [[4],[5],[6]],\n",
    "                   [[7],[8],[9]]]], dtype=np.float32)  #  ([]) 1차원 ([[],[]]) 2차원\n",
    "print(\"image의 shape : {}\".format(image.shape))  # (1,3,3,1)\n",
    "\n",
    "# Actrivation map을 위한 filter를 정의 (Width, height, color,filter개수)\n",
    "# filter (2,2,1,3)\n",
    "weight = np.array([[[[1,10,-1]],[[1,10,-1]]],[[[1,10,-1]],[[1,10,-1]]]])\n",
    "print(\"weight의 shape : {}\".format(weight.shape))\n",
    "      \n",
    "# stride = 1(가로,세로를 1씩 움직여요)\n",
    "# 이미지의 개수 생각않고 2차원으로 뽑겠다\n",
    "conv2d = tf.nn.conv2d(image,weight,\n",
    "                      strides=[1,1,1,1], padding=\"VALID\")\n",
    "# conv2d <- tf의 node\n",
    "# [1,1] <- 가운데가 실제 가로 세로 stride 앞과 뒤는 dummy 임의로 붙여줌\n",
    "# VALID : padding하지말아라 -> 사이즈 줄게됨\n",
    "print(\"conv2d의 shape : {}\".format(conv2d.shape))\n",
    "sess = tf.Session()\n",
    "conv2d = sess.run(conv2d)\n",
    "\n",
    "# pooling layer\n",
    "pool = tf.nn.max_pool(conv2d, ksize=[1,2,2,1], \n",
    "                      strides=[1,1,1,1],padding=\"SAME\")\n",
    "# 앞뒤 1 4차원 데이터를 mapping시키기 위한 dummy변수\n",
    "# SAME의 의미는 padding을 상하좌우에 붙인다는게 아니라 출력크기가 처음과 같게 해주도록 붙여준다는 것\n",
    "# stride 크기는 가로 ㅔ로 같게 잡는것이 좋음\n",
    "# 양옆의 1,1은 4차원 만들어주는 더미변수일뿐\n",
    "\n",
    "print(\"pool의 shape:{}\".format(pool.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### convolution 결과 이미지가 원본이미지에 비해 어떻게 다른지 눈으로 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "conv2d의 shape:(1, 14, 14, 5)\n",
      "conv2d_img의 shape:(1, 14, 14, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21429bc4da0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data Loading\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)\n",
    "\n",
    "img = mnist.train.images[0].reshape(28,28)\n",
    "plt.imshow(img, cmap=\"Greys\")\n",
    "\n",
    "# 해당 이미지를 Convolution 처리를 해보아요\n",
    "# 입력데이터 => (이미지개수. width, height, color) => (1,3,3,1)\n",
    "img = img.reshape(-1,28,28,1)  # 맨앞 이미지 수이므로 1이라고 써도 도지만 \n",
    "# -1쓰면 뒤에거 채우고 나머지 다 이미지 개수로 채움\n",
    "# reshape : 차원 바꿔줌\n",
    "\n",
    "# Activation map을 위한 filter를 정의\n",
    "# (width, height, color, filter개수)\n",
    "W = tf.Variable(tf.random_normal([3,3,1,5]), name=\"filter1\") # 랜덤으로 도출\n",
    "conv2d = tf.nn.conv2d(img,W,strides = [1,2,2,1],\n",
    "                     padding=\"SAME\")\n",
    "# 원래 데이터와 filter데이터 convolution\n",
    "    # strides가 1일 경우\" paddig=\"SAME\" 하면 원래 크기와 같게 나오지만 28,28\n",
    "    # strides가 2일 경우\" padding=\"SAME\" 하면 원래 크기의 절반크기로 출력됨 14,14\n",
    "\n",
    "print(\"conv2d의 shape:{}\".format(conv2d.shape))   # (1, 14, 14, 5)\n",
    "sess.run(tf.global_variables_initializer()) # tf.Variable 실행시켜주려고\n",
    "conv2d = sess.run(conv2d)\n",
    "\n",
    "# 이미지를 표현하게 위해서 축을 전환\n",
    "# (1,14,14,5) => (5,14,14,1) # filter당 하나씩 5개 있음\n",
    "conv2d_img = np.swapaxes(conv2d,0,3) # 축을바꿔줌 0번째 축과 3번째 축을 바꿔줌\n",
    "print(\"conv2d_img의 shape:{}\".format(conv2d.shape))\n",
    "plt.imshow(conv2d_img[1].reshape(14,14), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorflow-MNIST with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "cost:0.24849632382392883\n",
      "cost:0.14011162519454956\n",
      "cost:0.03827530890703201\n",
      "cost:0.1509752720594406\n",
      "cost:0.18645672500133514\n",
      "cost:0.18483661115169525\n",
      "cost:0.30755218863487244\n",
      "cost:0.27797287702560425\n",
      "cost:0.053989410400390625\n",
      "cost:0.0871821790933609\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)\n",
    "\n",
    "# Graph 초기화\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Placeholder\n",
    "X = tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "dout_rate = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "# Convolution Layer\n",
    "x_img = tf.reshape(X,[-1,28,28,1])   # convolution 들어가려면 4차원 이어야해\n",
    "W1 = tf.Variable(tf.random_normal([3,3,1,32]))\n",
    "# filter 랜덤으로 잡는거야 머신러닝 아니야\n",
    "L1 = tf.nn.conv2d(x_img,W1,strides=[1,1,1,1],padding=\"SAME\")\n",
    "L1 = tf.nn.relu(L1)  # 너무커지지않게 줄여줌\n",
    "L1 = tf.nn.max_pool(L1,ksize=[1,2,2,1], strides=[1,2,2,1],\n",
    "                   padding=\"SAME\")   # size를 반으로 줄임\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([3,3,32,64]))   # 3번째 거 32 <- channel 수\n",
    "L2 = tf.nn.conv2d(L1,W2,strides=[1,1,1,1],padding=\"SAME\")\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2,ksize=[1,2,2,1], strides=[1,2,2,1],\n",
    "                   padding=\"SAME\")\n",
    "\n",
    "# 이렇게 만든 데이터를 FC Layer에 넣어서 학습해야 해\n",
    "# 입력이 1차원으로 들어와야해\n",
    "# L2 2차원으로 들어와야해\n",
    "\n",
    "L2 = tf.reshape(L2,[-1,7*7*64])  # -1: 이미지의 개수 55000장, 64장의 학습한 이미지\n",
    "\n",
    "W3 = tf.get_variable(\"weight3\", shape = [7*7*64,256],\n",
    "                    initializer = tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]), name=\"bias1\")\n",
    "# depth가 이깊으로면깊을수록 연상이 안돼\n",
    "_layer1 = tf.nn.relu(tf.matmul(L2,W3)+b1)\n",
    "layer1 = tf.nn.dropout(_layer1, keep_prob=dout_rate)   # 256개 output을 다 뽑아내지 않겠다. node를 아예삭제하는게 아니라 \n",
    "# 기능을 상실키시는것\n",
    "# rate=0이 다 살아있는거\n",
    "# rate=0.3 => 30% 죽인 layer\n",
    "\n",
    "W4 = tf.get_variable(\"weight4\", shape=[256,256],\n",
    "                    initializer = tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([256]), name=\"bias2\")\n",
    "_layer2 = tf.nn.relu(tf.matmul(layer1,W4)+b2)\n",
    "layer2 = tf.nn.dropout(_layer2, keep_prob=dout_rate) \n",
    "    \n",
    "W5 = tf.get_variable(\"weight5\", shape=[256,10],\n",
    "                    initializer = tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([10]), name=\"bias3\")\n",
    "# 사실 sigmoid쓰나 softmax쓰나 같은결과, softmax는 전체 확률로 바뀌고 sigmoid에서 가장 큰 값이 softmax에서도\n",
    "# 가장 큰값인건 바뀌지 않음\n",
    "\n",
    "\n",
    "# Hypothesis\n",
    "logit= tf.matmul(layer2,W5) + b3\n",
    "H = tf.nn.relu(logit)\n",
    "# sigmoid를 해서 softmax하면 가장 효율적임#\n",
    "\n",
    "# cost\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit, labels=Y)) # 이건 그대로\n",
    "\n",
    "# train\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)    # 이것도 자주쓰이지만 큰 효과는 x\n",
    "\n",
    "# session chrlghk\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "num_of_epoch = 50   #반복횟수\n",
    "batch_size = 100\n",
    "\n",
    "for step in range(num_of_epoch):\n",
    "    num_of_iter = int(mnist.train.num_examples/batch_size)\n",
    "    cost_val=0\n",
    "                      \n",
    "    for i in range(num_of_iter):\n",
    "        batch_x,batch_y = mnist.train.next_batch(batch_size)   # x,y 100개씩 떼오기\n",
    "        _,cost_val = sess.run([train,cost], feed_dict = {X:batch_x, \n",
    "                                                         Y:batch_y,\n",
    "                                                         dout_rate:0.7})   # 30%끄고 학습 overfitting 피하려고\n",
    "    if step%5 ==0:\n",
    "        print(\"cost:{}\".format(cost_val))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.984000027179718\n"
     ]
    }
   ],
   "source": [
    "# Accuracy 측정\n",
    "predict = tf.argmax(H,1)\n",
    "correct = tf.equal(predict, tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype = tf.float32))\n",
    "\n",
    "print(\"정확도 : {}\".format(sess.run(accuracy, \n",
    "                               feed_dict={X:mnist.test.images,\n",
    "                                          Y:mnist.test.labels,\n",
    "                                          dout_rate:1})))\n",
    "# 학습은 overfitting 피하려고 30% 죽이고 하는데 정확도는 0으로 해줘야해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 혜준"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow-MNIST with CNN\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# Data Loading\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)\n",
    "\n",
    "# Graph 초기화\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Placeholder\n",
    "X = tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "keep_rate = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "# Convolution Layer\n",
    "x_img = tf.reshape(X,[-1,28,28,1]) # X를 이모양으로 바꿔\n",
    "W1 = tf.Variable(tf.random_normal([3,3,1,32])) # 3,3,1에 filter 32개 \n",
    "L1 = tf.nn.conv2d(x_img, W1, strides=[1,1,1,1], padding=\"SAME\") \n",
    "L1 = tf.nn.relu(L1) # convolution을 하면 값이 커지거나 작아지기때문에 relu를 해줍니다.\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\") # pooling도 여기서는 해줄게요\n",
    "# stride를 2로 잡고 padding을 해주었으니 size가 반으로 줄었겠죠 \n",
    "# 결과적으로 [None,14,14,32]\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([3,3,32,64])) # (새필터가로, 새필터세로, 이전에필터갯수, 새로운필터갯수)\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1,1,1,1], padding=\"SAME\") \n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "# stride를 2로 잡고 다시 padding을 해주었으니 size가 또 반으로 줄었겠죠\n",
    "# 결과적으로 [None,7,7,64]\n",
    "\n",
    "\n",
    "# 이렇게 만든 데이터를 FC Layer에 넣어서 학습해야 해요!\n",
    "L2 = tf.reshape(L2,[-1,7*7*64])\n",
    "\n",
    "W3 = tf.get_variable(\"weight3\", shape=[7*7*64,256],\n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]), name= \"bias1\")\n",
    "_layer1 = tf.nn.relu(tf.matmul(L2,W3) + b1) # 이렇게 하면 256개가 나옴\n",
    "layer1 = tf.nn.dropout(_layer1, keep_prob=keep_rate) # 위의 256개의 노드의 기능을 상실시키겠다.30%를 죽여서 넘기겠다.\n",
    "# cpu_env에서는 rate가 아니라 keep_prob으로 keep_rate는 남기고 싶은 퍼센트를 넣어주면 된다\n",
    "\n",
    "\n",
    "W4 = tf.get_variable(\"weight4\", shape=[256,256],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer()) # 초기화 방법       \n",
    "b2 = tf.Variable(tf.random_normal([256]), name=\"bias2\")\n",
    "_layer2 = tf.nn.relu(tf.matmul(layer1,W4) + b2)\n",
    "layer2 = tf.nn.dropout(_layer2, keep_prob=keep_rate)\n",
    "\n",
    "W5 = tf.get_variable(\"weight5\", shape=[256,10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer()) # 초기화 방법      \n",
    "b3 = tf.Variable(tf.random_normal([10]), name=\"bias3\")\n",
    "\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(layer2, W5) + b3\n",
    "H = tf.nn.relu(logit)\n",
    "\n",
    "\n",
    "# cost\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logit,\n",
    "                                                              labels = Y))\n",
    "\n",
    "# train\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "# Adamoptimizer가 더 좋은 성능을 가진 함수이다!!!\n",
    "\n",
    "# session, 초기화 \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "num_of_epoch = 30 \n",
    "batch_size = 100\n",
    "\n",
    "for step in range(num_of_epoch):\n",
    "    num_of_iter = int(mnist.train.num_examples / batch_size)\n",
    "    cost_val = 0\n",
    "    \n",
    "    for i in range(num_of_iter):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        _, cost_val = sess.run([train,cost], feed_dict={X:batch_x,\n",
    "                                                       Y:batch_y,\n",
    "                                                       keep_rate:0.7})\n",
    "        \n",
    "    if step % 3 == 0:\n",
    "        print(\"Cost : {}\".format(cost_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[CPU_ENV]",
   "language": "python",
   "name": "cpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
