{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0116\n",
    "\n",
    "\n",
    "객체 => 기능 + 데이터가 같이 존재하는 하나의 덩어리  \n",
    "하나의 덩어리  => 일정 크기의 메모리 공간  \n",
    "객체 = instance = object  \n",
    "정보를 기반으로 객체를 만든다  \n",
    "객체를 만들고 싶어 => 객체가 가지는 기능이 어떤 기능인지... 저장할 데이터가 어떻게 저장되는지를 알아야 객체를 만들 수 있다  \n",
    "객체를 만들기 위해서는 만들 객체에 대한 정보가 (어떤기능이 있는지, 데이터를 어떻게 저장할 건지) 필요해  \n",
    "\n",
    "\n",
    "객체를 만들기 위해서 필요한 정보를 기술해 놓은 것 => **class!**\n",
    "\n",
    "\n",
    "객체를 생성하기 위해서 class부터 정의해 보자  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소나타 객체가 생성되었어요!!\n",
      "그랜저 객체가 생성되었어요!!\n"
     ]
    }
   ],
   "source": [
    "# class definition\n",
    "class Car:\n",
    "    # 생성자 => class로부터 객체가 만들어질때\n",
    "    #           무조건 호출되는 함수\n",
    "    # slef => 현재사용되는 객체에대한 reference\n",
    "    # \n",
    "    def __init__(self, name):   # 함수니까 인자받아들여\n",
    "        \n",
    "        self.myName = name\n",
    "        self.myList = [1,2,3,4]   # 각각의 객체안에 list들어있음\n",
    "        # 객체 2개 만들어지고 리스트 2개씩\n",
    "        # 자료구조 여러개 만들어서 객체라는 큰 하나의 구조를 만듦\n",
    "        # 객체 : 추상 데이터 타입\n",
    "        #        기존데이터 타입을 만들어서 새로운 타입을 만듦\n",
    "        print(\"{} 객체가 생성되었어요!!\".format(self.myName))\n",
    "\n",
    "car1 = Car(\"소나타\")  # 객체를 생성하고 변수에 저장\n",
    "car2 = Car(\"그랜저\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class \n",
    "class는 객체를 만들기 위해서 필요한 툴  \n",
    "class안에 기술된 정보를 바탕으로 일정 메모리 영역을 확보할 수 있고 이 영역을 객체!  \n",
    "객체 :메모리 공간  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "객체가 생성되요\n",
      "자동차가 전진해요!\n",
      "소나타\n",
      "그랜저\n",
      "100\n",
      "객체가 생성되요\n",
      "자동차가 후진해요!\n"
     ]
    }
   ],
   "source": [
    "class Car:\n",
    "    # constructor(생성자) => 함수\n",
    "    \n",
    "    # 객체가 처음 만들어질 때 무조건 호출 되요\n",
    "    # 객체가 가지는 변수를 특정 값으로 초기화\n",
    "    # 초기화를 위해서 인자를 받아들인다\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"객체가 생성되요\")\n",
    "        # class 로부터 파생된 객체가 가질 수 있는 data는 여기에 명시해요!\n",
    "        self.car_name = \"소나타\"   # 내가 사용할 변수 만듦\n",
    "        \n",
    "    # 기능을 위한 함수(여러개 나올 수 있어요)\n",
    "    def go_front(self):   # self라는 인자가 들어옴, 현재 객체를 지칭하는 reference\n",
    "        self.my_var = 100\n",
    "        my_bar = 200      # instance variable : 이 함수 내에서 일시적으로 사용하는 함수로 인식\n",
    "        print(\"자동차가 전진해요!\")\n",
    "    # self를 해줘야 객체가 가지는 변수로 인식하네\n",
    "    \n",
    "    def backward(self):\n",
    "        print(\"자동차가 후진해요!\")\n",
    "        \n",
    "        # go_front backward 기능을 가지고 있어\n",
    "        \n",
    "        \n",
    "car1  = Car()   # self다음에 나오는것을 넣어줘야해\n",
    "                # car1이 하나의 객체\n",
    "                # 생성자가 호출해서 객체가 만들어지고\n",
    "car1.go_front()\n",
    "print(car1.car_name) \n",
    "car1.car_name = \"그랜저\"    # 값을 바꿔줌\n",
    "print(car1.car_name)\n",
    "# print(car1.my_bar)\n",
    "car2 = Car()    # 객체가 만들어짐\n",
    "                # car2는 하나의 객체\n",
    "                # 별도의 객체\n",
    "car2.backward() # \".\" => dot operator\n",
    "                # 연산자\n",
    "# class 외부에서 변수를 사용하려면 self가 붙어야해\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "객체가 생성되요\n",
      "자동차가 전진해요!\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "class Car:\n",
    "    # constructor(생성자) => 함수\n",
    "    \n",
    "    # 객체가 처음 만들어질 때 무조건 호출 되요\n",
    "    # 객체가 가지는 변수를 특정 값으로 초기화\n",
    "    # 초기화를 위해서 인자를 받아들인다\n",
    "    \n",
    "    def __init__(self,name):\n",
    "        print(\"객체가 생성되요\")\n",
    "        # class 로부터 파생된 객체가 가질 수 있는 data는 여기에 명시해요!\n",
    "        self.car_name = name   # 내가 사용할 변수 만듦\n",
    "        self.fuel = 100\n",
    "        \n",
    "    # 기능을 위한 함수(여러개 나올 수 있어요)\n",
    "    def go_front(self):   # self라는 인자가 들어옴, 현재 객체를 지칭하는 reference\n",
    "        self.my_var = 100\n",
    "        my_bar = 200      # instance variable : 이 함수 내에서 일시적으로 사용하는 함수로 인식\n",
    "        print(\"자동차가 전진해요!\")\n",
    "    # self를 해줘야 객체가 가지는 변수로 인식하네\n",
    "        self.fuel = self.fuel - 5\n",
    "        \n",
    "    def get_fuel(self):   # 연료량을 알아내는 함수\n",
    "        return self.fuel\n",
    "    \n",
    "    def backward(self):\n",
    "        print(\"자동차가 후진해요!\")\n",
    "        \n",
    "car1 = Car(\"소나타\")\n",
    "car1.go_front()\n",
    "print(car1.get_fuel())\n",
    "\n",
    "# 이렇게 하면 tf graph 다 가지고 있어\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN(ensemble)을 class를 이용해서 구현해 보자\n",
    "ensemble은 여러개의 CNN model을 만들어서 이용  \n",
    "객체를 만들어서 각 객체에 CNN model을 하나씩 저장  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "객체가 생성되었다!\n",
      "텐서플로우 그래프를 그려요\n",
      "정확도를 구해요\n",
      "객체가 생성되었다!\n",
      "텐서플로우 그래프를 그려요\n",
      "정확도를 구해요\n",
      "객체가 생성되었다!\n",
      "텐서플로우 그래프를 그려요\n",
      "정확도를 구해요\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value conv2d/kernel\n\t [[Node: conv2d/kernel/read = Identity[T=DT_FLOAT, _class=[\"loc:@conv2d/kernel\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv2d/kernel)]]\n\nCaused by op 'conv2d/kernel/read', defined at:\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\asyncio\\base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\asyncio\\base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-39-55e8ce55f6d8>\", line 117, in <module>\n    models = [CnnModel(sess, mnist) for x in range(num_of_model)]   # x가 0~9까지 10번반복\n  File \"<ipython-input-39-55e8ce55f6d8>\", line 117, in <listcomp>\n    models = [CnnModel(sess, mnist) for x in range(num_of_model)]   # x가 0~9까지 10번반복\n  File \"<ipython-input-39-55e8ce55f6d8>\", line 14, in __init__\n    self.build_graph()\n  File \"<ipython-input-39-55e8ce55f6d8>\", line 37, in build_graph\n    activation = tf.nn.relu)   # filter안쓰고 개수, 사이즈 알려줘야해 -> 함수의 인자로 넣어줌\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\layers\\convolutional.py\", line 614, in conv2d\n    return layer.apply(inputs)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 762, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 636, in __call__\n    self.build(input_shapes)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\layers\\convolutional.py\", line 143, in build\n    dtype=self.dtype)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 504, in add_variable\n    partitioner=partitioner)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1262, in get_variable\n    constraint=constraint)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1097, in get_variable\n    constraint=constraint)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 435, in get_variable\n    constraint=constraint)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 404, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 806, in _get_single_variable\n    constraint=constraint)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 229, in __init__\n    constraint=constraint)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 376, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 127, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 2728, in identity\n    \"Identity\", input=input, name=name)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value conv2d/kernel\n\t [[Node: conv2d/kernel/read = Identity[T=DT_FLOAT, _class=[\"loc:@conv2d/kernel\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv2d/kernel)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value conv2d/kernel\n\t [[Node: conv2d/kernel/read = Identity[T=DT_FLOAT, _class=[\"loc:@conv2d/kernel\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv2d/kernel)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-55e8ce55f6d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[0mmodel_np\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_examples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_of_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m     \u001b[0mmodel_np\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_np\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_h\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[0mpredict_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_np\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-39-55e8ce55f6d8>\u001b[0m in \u001b[0;36mget_h\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_h\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         self.H_val=sess.run(self.H, feed_dict={self.X:self.mnist.test.images,\n\u001b[1;32m--> 100\u001b[1;33m                                                self.dropout_rate:0})\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mH_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1363\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1365\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value conv2d/kernel\n\t [[Node: conv2d/kernel/read = Identity[T=DT_FLOAT, _class=[\"loc:@conv2d/kernel\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv2d/kernel)]]\n\nCaused by op 'conv2d/kernel/read', defined at:\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\asyncio\\base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\asyncio\\base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-39-55e8ce55f6d8>\", line 117, in <module>\n    models = [CnnModel(sess, mnist) for x in range(num_of_model)]   # x가 0~9까지 10번반복\n  File \"<ipython-input-39-55e8ce55f6d8>\", line 117, in <listcomp>\n    models = [CnnModel(sess, mnist) for x in range(num_of_model)]   # x가 0~9까지 10번반복\n  File \"<ipython-input-39-55e8ce55f6d8>\", line 14, in __init__\n    self.build_graph()\n  File \"<ipython-input-39-55e8ce55f6d8>\", line 37, in build_graph\n    activation = tf.nn.relu)   # filter안쓰고 개수, 사이즈 알려줘야해 -> 함수의 인자로 넣어줌\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\layers\\convolutional.py\", line 614, in conv2d\n    return layer.apply(inputs)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 762, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 636, in __call__\n    self.build(input_shapes)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\layers\\convolutional.py\", line 143, in build\n    dtype=self.dtype)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 504, in add_variable\n    partitioner=partitioner)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1262, in get_variable\n    constraint=constraint)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1097, in get_variable\n    constraint=constraint)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 435, in get_variable\n    constraint=constraint)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 404, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 806, in _get_single_variable\n    constraint=constraint)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 229, in __init__\n    constraint=constraint)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 376, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 127, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 2728, in identity\n    \"Identity\", input=input, name=name)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\student\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value conv2d/kernel\n\t [[Node: conv2d/kernel/read = Identity[T=DT_FLOAT, _class=[\"loc:@conv2d/kernel\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv2d/kernel)]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist  import input_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 그래프 초기화\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# class에 만들어진 객체안에 tf 그래프 넣을거야\n",
    "\n",
    "class CnnModel:\n",
    "    def __init__(self,session, data):\n",
    "        print(\"객체가 생성되었다!\")\n",
    "        self.build_graph()\n",
    "        self.sess=session  # 객체를 만들때 session을 받아오겠다\n",
    "                            # 각각의 모델에 넘겨줌\n",
    "                            # 각자 만들필요 없이 쓸 수 있어\n",
    "        self.mnist = data\n",
    "        self.get_accuacy()\n",
    "\n",
    "        \n",
    "    def build_graph(self):\n",
    "        print(\"텐서플로우 그래프를 그려요\")\n",
    "        \n",
    "        # 2.1 placeholder\n",
    "        self.X = tf.placeholder(shape = [None,784], dtype=tf.float32)\n",
    "        self.Y = tf.placeholder(shape = [None,10], dtype=tf.float32)\n",
    "        self.dropout_rate = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "        # 2.2 Convoluion Layer\n",
    "        # 입력데이터는 4차원!\n",
    "        x_img = tf.reshape(self.X, [-1,28,28,1])  # 3차원\n",
    "        L1 = tf.layers.conv2d(inputs = x_img, filters=32,\n",
    "                              kernel_size=[3,3],\n",
    "                              padding = \"SAME\",\n",
    "                              strides = 1,\n",
    "                              activation = tf.nn.relu)   # filter안쓰고 개수, 사이즈 알려줘야해 -> 함수의 인자로 넣어줌\n",
    "\n",
    "        L1 = tf.layers.max_pooling2d(inputs=L1, pool_size=[2,2],\n",
    "                                     padding=\"SAME\",\n",
    "                                     strides=2)\n",
    "\n",
    "        L1 = tf.layers.dropout(inputs=L1, rate=self.dropout_rate)\n",
    "\n",
    "\n",
    "        L2 = tf.layers.conv2d(inputs = L1, filters=64,\n",
    "                              kernel_size=[3,3],\n",
    "                              padding = \"SAME\",\n",
    "                              strides = 1,\n",
    "                              activation = tf.nn.relu) \n",
    "        L2 = tf.layers.max_pooling2d(inputs=L2, pool_size=[2,2],\n",
    "                                     padding=\"SAME\",\n",
    "                                     strides=2)\n",
    "        L2 = tf.layers.dropout(inputs=L2, rate=self.dropout_rate)\n",
    "\n",
    "        # 2.3 FC Layer => dense layer\n",
    "        L2 = tf.reshape(L2,[-1,7*7*64])# 4차원을 2차원으로 reshape\n",
    "\n",
    "        dense1 = tf.layers.dense(inputs=L2, units=256,\n",
    "                                 activation=tf.nn.relu)\n",
    "        dense1 = tf.layers.dropout(inputs=dense1, rate=self.dropout_rate)\n",
    "\n",
    "        dense2 = tf.layers.dense(inputs=dense1, units=128,\n",
    "                                 activation=tf.nn.relu)\n",
    "        dense2 = tf.layers.dropout(inputs=dense2, rate=self.dropout_rate)\n",
    "\n",
    "        dense3 = tf.layers.dense(inputs=dense2, units=512,\n",
    "                                 activation=tf.nn.relu)\n",
    "        dense3 = tf.layers.dropout(inputs=dense3, rate=self.dropout_rate)\n",
    "\n",
    "        # 몇개로 잡을 것인가만 정해주면돼\n",
    "\n",
    "        self.H = tf.layers.dense(inputs=dense3, units=10)    # 마지막에 relu안잡아줘\n",
    "\n",
    "        # cost\n",
    "        self.cost = tf.losses.softmax_cross_entropy(self.Y,self.H)\n",
    "\n",
    "        # train\n",
    "        self.train = tf.train.AdamOptimizer(learning_rate=0.01).minimize(self.cost)\n",
    "        \n",
    "    def train_graph(self):\n",
    "        print(\"텐서플로우 그래프를 학습시켜요\")\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        num_of_epoch = 10\n",
    "        batch_size = 10\n",
    "\n",
    "        for step in range(num_of_epoch):\n",
    "            num_of_iter = int(self.mnist.train.num_examples/batch_size)\n",
    "            cost_val = 0\n",
    "            for i in range(num_of_iter):\n",
    "                batch_x, batch_y = self.mnist.train.next_batch(batch_size)        \n",
    "                _, cost_val = self.sess.run([self.train,self.cost],\n",
    "                                            feed_dict = {self.X:batch_x,\n",
    "                                                         self.Y:batch_y,\n",
    "                                                         self.dropout_rate:0.3}) # 30% 끄고 학습해라\n",
    "            if step%1==0:\n",
    "                print(\"cost:{}\".format(cost_val))\n",
    "    def get_h(self):\n",
    "        self.H_val=sess.run(self.H, feed_dict={self.X:self.mnist.test.images,\n",
    "                                               self.dropout_rate:0})\n",
    "        return self.H_val\n",
    "                \n",
    "    def get_accuacy(self):\n",
    "        print(\"정확도를 구해요\")\n",
    "\n",
    "    def grt_prediction(self):\n",
    "        print(\"예측값을 구해요\")\n",
    "    \n",
    "    # 기능을 따로 나눠서 \n",
    "\n",
    "    \n",
    "# 모델 10 개를 만들거에요! => 객체 10개를 만들거에요\n",
    "sess = tf.Session()\n",
    "\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)\n",
    "num_of_model = 3\n",
    "models = [CnnModel(sess, mnist) for x in range(num_of_model)]   # x가 0~9까지 10번반복\n",
    "# 객체 3개가 그래프를 따로 갖는다\n",
    "# 그래프가 객체 안에 1개씩 들어감\n",
    "\n",
    "model_np=np.zeros([mnist.test.num_examples,10])\n",
    "for i in range(num_of_model):\n",
    "    model_np = model_np + models[i].get_h()\n",
    "\n",
    "predict_result = np.argmax(model_np,1)\n",
    "true_result = np.argmax(mnist.test.labels,1)\n",
    "correct = np.equal(predict_result, true_result)\n",
    "accuracy = np.mean(correct)\n",
    "print(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "dropout() got an unexpected keyword argument 'rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-30b3fba6a0df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[0mnum_of_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[0mmnist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./data/mnist\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m \u001b[0mmodels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCnnModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_of_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[0mmodel_np\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_examples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-30b3fba6a0df>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[0mnum_of_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[0mmnist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./data/mnist\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m \u001b[0mmodels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCnnModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_of_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[0mmodel_np\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_examples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-30b3fba6a0df>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, session, data)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# 객체 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmnist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-30b3fba6a0df>\u001b[0m in \u001b[0;36mbuild_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mL2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mdense1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mL2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mdense1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdense1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mdense2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdense1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: dropout() got an unexpected keyword argument 'rate'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 그래프 초기화\n",
    "tf.reset_default_graph()\n",
    "\n",
    "class CnnModel:\n",
    "    # 객체 생성\n",
    "    def __init__(self,session,data):\n",
    "        self.build_graph()\n",
    "        self.mnist = data\n",
    "        self.train_graph()\n",
    "        # Session & 초기화\n",
    "        self.sess = session \n",
    "    \n",
    "    # 그래프 그리는 함수\n",
    "    def build_graph(self):\n",
    "       \n",
    "        # 2.1 placeholder\n",
    "        self.X = tf.placeholder(shape=[None,784], dtype=tf.float32)  # 학습할 때 필요하니까 다 self\n",
    "        self.Y = tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "        self.dropout_rate = tf.placeholder(dtype=tf.float32)  \n",
    "\n",
    "        # 2.2 Convolution Layer\n",
    "        x_img = tf.reshape(self.X,[-1,28,28,1])  # self 붙일 필요 없음. 다른 함수에서는 이거 안쓰므로\n",
    "\n",
    "        L1 = tf.layers.conv2d(inputs=x_img, filters=32, kernel_size=[3,3], padding=\"SAME\",\n",
    "                            strides=1,activation=tf.nn.relu)  \n",
    "        L1 = tf.layers.max_pooling2d(inputs=L1, pool_size=[2,2],padding=\"SAME\", strides=2)\n",
    "        L1 = tf.layers.dropout(inputs=L1, rate=self.dropout_rate)\n",
    "\n",
    "        L2 = tf.layers.conv2d(inputs=L1, filters=64, kernel_size=[3,3], padding=\"SAME\",\n",
    "                            strides=1, activation=tf.nn.relu) \n",
    "        L2 = tf.layers.max_pooling2d(inputs=L2, pool_size=[2,2],padding=\"SAME\", strides=2)\n",
    "        L2 = tf.layers.dropout(inputs=L2, rate=self.dropout_rate)\n",
    "\n",
    "        # 2.3 FC layer -> dense layer \n",
    "        L2 = tf.reshape(L2, [-1,7*7*64])\n",
    "        dense1 = tf.layers.dense(inputs=L2, units=256, activation=tf.nn.relu)\n",
    "        dense1 = tf.nn.dropout(dense1, rate=self.dropout_rate)  \n",
    "\n",
    "        dense2 = tf.layers.dense(inputs=dense1, units=128, activation=tf.nn.relu)\n",
    "        dense2 = tf.nn.dropout(dense2, rate=self.dropout_rate)\n",
    "\n",
    "        dense3 = tf.layers.dense(inputs=dense2, units=512, activation=tf.nn.relu)\n",
    "        dense3 = tf.nn.dropout(dense3, rate=self.dropout_rate)\n",
    "\n",
    "        self.H = tf.layers.dense(inputs=dense3, units=10)   # 외부에서 prediction할 때 쓸거니까 self\n",
    "\n",
    "        # cost \n",
    "        self.cost = tf.losses.softmax_cross_entropy(self.Y,self.H)\n",
    "\n",
    "        # train\n",
    "        self.train = tf.train.AdamOptimizer(learning_rate=0.001).minimize(self.cost)\n",
    "\n",
    "        \n",
    "    # 그래프 그린 후 학습\n",
    "    def train_graph(self):  # self를 안붙이면 변수의 가동 범위가 해당 함수밖에 안됨\n",
    "        sess.run(tf.global_variables_initializer()) # session 초기화\n",
    "        # 학습 - epoch, batch 등 \n",
    "        num_of_epoch = 10\n",
    "        batch_size = 100\n",
    "        for step in range(num_of_epoch):\n",
    "            num_of_iter = int(self.mnist.train.num_examples/batch_size)\n",
    "            cost_val = 0\n",
    "            for i in range(num_of_iter):\n",
    "                batch_x, batch_y = self.mnist.train.next_batch(batch_size)        \n",
    "                _, cost_val = sess.run([self.train,self.cost],feed_dict={self.X:batch_x,\n",
    "                                                                         self.Y:batch_y,\n",
    "                                                                         self.dropout_rate:0.3})\n",
    "\n",
    "    def get_h(self):\n",
    "        self.H_val = sess.run(self.H, feed_dict={self.X: self.mnist.test.images,\n",
    "                                                 self.dropout_rate:0})\n",
    "        return self.H_val\n",
    "        \n",
    "\n",
    "# 모델 10개 만들기 -> 객체 10개 만들기\n",
    "sess = tf.Session()\n",
    "\n",
    "num_of_model = 3\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)\n",
    "models = [CnnModel(sess,mnist) for x in range(num_of_model)]\n",
    "\n",
    "model_np = np.zeros([mnist.test.num_examples,10])\n",
    "for i in range(num_of_model):\n",
    "    model_np = model_np + models[i].get_h()\n",
    "\n",
    "predict_result = np.argmax(model_np,1)\n",
    "true_result = np.argmax(mnist.test.labels,1)\n",
    "correct = np.equal(predict_result,true_result)\n",
    "accuracy = np.mean(correct)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as pilimg\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Read image\n",
    "img = Image.open(\"./data/digit-recognizer/7.jpg\").convert('L')\n",
    "resize_img = img.resize((28,28))\n",
    "# Display image\n",
    "# resize_img.show()\n",
    " \n",
    "# Fetch image pixel data to numpy array\n",
    "pix_g = np.array(resize_img)\n",
    "\n",
    "plt.imshow(pix_g, cmap='gray')\n",
    "\n",
    "pix_dd=255-pix_g\n",
    "pix_dd\n",
    "plt.imshow(pix_dd, cmap='gray')\n",
    "pix_dd=pix_dd.reshape([1,-1])\n",
    "pix_dd\n",
    "prediction_data = scaler.transform(pix_dd)\n",
    "result = sess.run(tf.argmax(H,1), feed_dict={X:pix_dd})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "# 랜덤으로 하나의 데이터를 추출해서 그놈을 이용해서 prediction을 한 후 결과를 비교해 보자\n",
    "\n",
    "\n",
    "result = sess.run(tf.argmax(H,1), feed_dict={X:pix_dd})[0]\n",
    "\n",
    "\n",
    "print(\"Label : {}\".format(sess.run(tf.argmax(test_y_data[r:r+1], axis=1))))\n",
    "\n",
    "print(\"Predict :{}\".format(sess.run(tf.argmax(H,1), \n",
    "         feed_dict={X:pix_dd})))    # 2차원\n",
    "\n",
    "plt.imshow(pix_dd.reshape(28,28), cmap=\"Greys\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[CPU_ENV]",
   "language": "python",
   "name": "cpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
