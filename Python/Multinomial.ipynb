{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression을 그림으로 알아보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost값은 : 1.99136483669281\n",
      "Cost값은 : 0.36829784512519836\n",
      "Cost값은 : 0.33051368594169617\n",
      "Cost값은 : 0.30338674783706665\n",
      "Cost값은 : 0.313737690448761\n",
      "Cost값은 : 0.4559189975261688\n",
      "Cost값은 : 0.16748619079589844\n",
      "Cost값은 : 0.16147112846374512\n",
      "Cost값은 : 0.16270576417446136\n",
      "Cost값은 : 0.20057576894760132\n",
      "[1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import mglearn\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "# warning이 나와도 출력되지 않아\n",
    "\n",
    "x,y = mglearn.datasets.make_forge()\n",
    "# mglearn이 갖고 있는 datasets들 중에 \n",
    "x\n",
    "# 실수값이 들어있는 2차열 배열\n",
    "y\n",
    "# 1010\n",
    "\n",
    "# logistic regression이랑 같아\n",
    "# x값과 y값이 들어가서 logistic이 될수있는 데이터\n",
    "\n",
    "# 먼저 간단하게 scatter(산점도)를 그려보자\n",
    "# y값이 0인 x를 추출해서 x의 첫번째 컬럼을 x축으로,\n",
    "# x의 두번째 컬럼을 y축으로 scatter를 그려보자\n",
    "\n",
    "blue = x[y==0]\n",
    "orange = x[y==1]\n",
    "\n",
    "plt.scatter(blue[:,0],blue[:,1])\n",
    "# 모든행에 대한 첫번째열에있는 애들\n",
    "plt.scatter(orange[:,0],orange[:,1])\n",
    "\n",
    "## manchine learning(Logistic Regression)\n",
    "### train data set( tset data set 은 넘어가 )\n",
    "train_x_data = x\n",
    "train_y_data = y.reshape([-1,1])\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape = [None,2], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape = [None,1], dtype=tf.float32)\n",
    "\n",
    "# Weight, bias\n",
    "W = tf.Variable(tf.random_normal([2,1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "# W 하나가 아니라 내부적으로 값 2개 가져\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# Cost(Loss) function\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit,\n",
    "                                                              labels=Y))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.5).minimize(cost)\n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습진행\n",
    "for step in range(3000):\n",
    "    _,cost_val = sess.run([train,cost], feed_dict={X : train_x_data,\n",
    "                                                  Y : train_y_data})\n",
    "    if step% 300 ==0:\n",
    "        print(\"Cost값은 : {}\".format(cost_val))\n",
    "\n",
    "        \n",
    "        \n",
    "# 정확도 측정(Accuracy) : 95% 이상 나오면 쓸만한 모델\n",
    "# Prediction(예측)\n",
    "result = sess.run(H, feed_dict = {X : [[9,4]]})  # 0.8 -> 1로 간주하겠어\n",
    "plt.scatter(9,4)\n",
    "\n",
    "model = LogisticRegression()\n",
    "myModel = model.fit(x,y)  # logistic model 학습\n",
    "print(myModel.predict([[9,4]]))\n",
    "# 9,4가 들어가면 1!\n",
    "\n",
    "mglearn.plots.plot_2d_separator(myModel,x,fill=False,\n",
    "                                eps=0.5,alpha=0.7)\n",
    "# mglear이 가지고 있는 plots에 plot~\n",
    "# logistic으로 만든 model 그림으로 그려봐\n",
    "# 우리가 logistic만든것은 0과 1의 경계 선을 만든것\n",
    "# 선위에쪽 1, 선 아래쪽 0\n",
    "# logistic : 0과 1을 구분짓는 가장 적절한 선을 찾는것\n",
    "# linear : 데이터에 가장 적합한 직선\n",
    "\n",
    "# 두개의 x값,\n",
    "# x쪽 데이터가 3개는 3차원 공간으로 표현해야하는데, 공간안에 각점들이 찍힘\n",
    "# 공간안에 가로지르는것은 선이 아니라 면이됨\n",
    "\n",
    "# 과적합 : 너무데이터에 딱 맞는 결과 -> 실제로는 안좋은 결과값\n",
    "# 약간의 오류가 있어보이지만 (파란색 위 오랜지 밑) 나중에 실제 데이터 예측할때 좋은 hyper plan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1cad8c58cc0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logistic을 multinomial로 확장해보자\n",
    "# x쪽데이터는 시험성적과 출석점수\n",
    "# y쪽데이터는 학점\n",
    "x = np.array([[10,5],\n",
    "             [9,5],\n",
    "             [5,1],\n",
    "             [4,2],\n",
    "              [1,3]])\n",
    "y = np.array([[\"A\"],\n",
    "              [\"A\"],\n",
    "              [\"B\"],\n",
    "              [\"B\"],\n",
    "              [\"C\"]])\n",
    "# 학습이 안돼\n",
    "\n",
    "plt.scatter(x[0:2,0],x[0:2,1])    # A등급의 점을 찍어보자\n",
    "plt.scatter(x[2:4,0],x[2:4,1])    # B등급의 점을 찍어보자\n",
    "plt.scatter(x[4,0],x[4,1])    # C등급의 점을 찍어보자\n",
    "# 로지스틱 합쳐서 얘들 만들 수 잇아!!\n",
    "# 3개의 로지스틱 hyper plan 으로 표현됨\n",
    "# a,b,c,를 기준으로 몇 퍼센트 각각\n",
    "# 로지스틱의 확장판\n",
    "# 가설 자체가 바뀌게 됨 가설이 여러개 들어가기 때문\n",
    "# cost함수도 바뀜 simoid -> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성적, 출석 =>  \"A\"   \n",
    "#                \"B\"\n",
    "#                \"C\"\n",
    "#  각각의 결과가 하나의 행\n",
    "# 세개ㅔ의 식 하나로 함침\n",
    "# 하나씩 sigmoid'가가보자해\n",
    "# 세개 중에 어떤게 될 가능성이 높은가? 를 구하는 것\n",
    "# probability 구해줭->softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost값은:20.325159072875977\n",
      "cost값은:1.1612226963043213\n",
      "cost값은:0.9500489830970764\n",
      "cost값은:0.6700853109359741\n",
      "cost값은:0.5518797039985657\n",
      "cost값은:0.4989664852619171\n",
      "cost값은:0.4391480088233948\n",
      "cost값은:0.05071975663304329\n",
      "cost값은:0.04611677676439285\n",
      "cost값은:0.042725127190351486\n",
      "정확도 : 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as df\n",
    "\n",
    "# train data set\n",
    "train_x_data = [[10,7,8,5],\n",
    "               [8,8,9,4],\n",
    "               [7,8,2,3],\n",
    "               [6,3,9,3],\n",
    "               [7,5,7,4],\n",
    "               [3,5,6,2],\n",
    "               [2,4,3,1]]\n",
    "\n",
    "train_y_data = [[1,0,0],   # one hot encoding형태\n",
    "               [1,0,0],\n",
    "               [0,1,0],\n",
    "               [0,1,0],\n",
    "               [0,1,0],\n",
    "               [0,0,1],\n",
    "               [0,0,1]]\n",
    "\n",
    "# placeholder\n",
    "X =  tf.placeholder(shape =[None,4], dtype=tf.float32)\n",
    "Y =  tf.placeholder(shape =[None,3], dtype=tf.float32)\n",
    "\n",
    "# Weight, bias\n",
    "W = tf.Variable(tf.random_normal([4,3]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([3]), name=\"bias\")\n",
    "\n",
    "# 실제 구하는 값은 12개\n",
    "\n",
    "# hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "# H = tf.sigmoid  # 각각의 확률이 나와서 한번에 \n",
    "H = tf.nn.softmax(logit) # 이놈이 변경돼!\n",
    "\n",
    "# ocost function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,\n",
    "                                                              labels=Y))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.1).minimize(cost)\n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "# 그래프를 실행하기 위한놈\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# W와 b를 초기화 시키는 것\n",
    "\n",
    "# 학습\n",
    "for step in range(3000):\n",
    "    _,cost_val = sess.run([train,cost], feed_dict={X:train_x_data,\n",
    "                                                   Y:train_y_data})\n",
    "    if step%300==0:\n",
    "        print(\"cost값은:{}\".format(cost_val))\n",
    "        \n",
    "# Accuracy(정확도)\n",
    "#predict = tf.cast(H>0.5, dtype=tf.float32)\n",
    "sess.run(H, feed_dict={X:[[10,8,9,5]]})\n",
    "predict = tf.argmax(H, axis=1)\n",
    "# 데이터가 있을 때 열방향한행에서의 최대값이 몇번째ㄱ에 있는가\n",
    "# 가장 큰값의 index번호를 리턴\n",
    "# 각각의 예측치에 대한 index번호\n",
    "# 가장 큰값이 어디에 있는가\n",
    "correct = tf.equal(predict, tf.argmax(Y,axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "print(\"정확도 : {}\".format(sess.run(accuracy,\n",
    "                                feed_dict = {X:train_x_data,\n",
    "                                             Y:train_y_data})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMI데이터를 학습한 후 자신의 키와 몸무게를 넣어서\n",
    "# 자신의 상태를 확인해보자\n",
    "# bmi.csv를 가져가서 multinomial문제를 학습해보아요\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"./data/bmi.csv\", skiprows=3)\n",
    "train_x_data = data_df[[\"height\",\"weight\"]].values\n",
    "train_y_data = data_df[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.shape\n",
    "train_num = int(data_df.shape[0] * 0.8)    #712\n",
    "train_num\n",
    "test_num = data_df.shape[0] - train_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test data set\n",
    "train_x_data = data_df[[\"height\",\"weight\"]][:train_num].values\n",
    "test_x_data = data_df[[\"height\",\"weight\"]][train_num:].values\n",
    "\n",
    "train_y_data = data_df[\"label\"][:train_num].values\n",
    "test_y_data = data_df[\"label\"][train_num:].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 값이 너무 크니 minmax scale \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "train_x_data = MinMaxScaler().fit_transform(train_x_data)\n",
    "\n",
    "# 더미변수로 바꿔주기\n",
    "train_y_data = pd.get_dummies(train_y_data) \n",
    "test_y_data = pd.get_dummies(test_y_data) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost값은:1.2960156202316284\n",
      "cost값은:0.6598236560821533\n",
      "cost값은:0.5611627101898193\n",
      "cost값은:0.5049108862876892\n",
      "cost값은:0.46657299995422363\n",
      "cost값은:0.4377782940864563\n",
      "cost값은:0.41487154364585876\n",
      "cost값은:0.39596033096313477\n",
      "cost값은:0.3799395263195038\n",
      "cost값은:0.36610499024391174\n",
      "정확도 : 0.32199999690055847\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'prediction_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-142-68ba57ac6d05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m                                              Y:test_y_data})))\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mprediction_data\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'prediction_data' is not defined"
     ]
    }
   ],
   "source": [
    "# placeholder\n",
    "X =  tf.placeholder(shape =[None,2], dtype=tf.float32)\n",
    "Y =  tf.placeholder(shape =[None,3], dtype=tf.float32)\n",
    "\n",
    "# Weight, bias\n",
    "W = tf.Variable(tf.random_normal([2,3]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([3]), name=\"bias\")\n",
    "\n",
    "# 실제 구하는 값은 12개\n",
    "\n",
    "# hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "# H = tf.sigmoid  # 각각의 확률이 나와서 한번에 \n",
    "H = tf.nn.softmax(logit) # 이놈이 변경돼!\n",
    "\n",
    "# ocost function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,\n",
    "                                                              labels=Y))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.1).minimize(cost)\n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "# 그래프를 실행하기 위한놈\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# W와 b를 초기화 시키는 것\n",
    "\n",
    "# 학습\n",
    "for step in range(3000):\n",
    "    _,cost_val = sess.run([train,cost], feed_dict={X:train_x_data,\n",
    "                                                   Y:train_y_data})\n",
    "    if step%300==0:\n",
    "        print(\"cost값은:{}\".format(cost_val))\n",
    "        \n",
    "# # Accuracy(정확도)\n",
    "# #predict = tf.cast(H>0.5, dtype=tf.float32)\n",
    "# sess.run(H, feed_dict={X:[[159,50]]})\n",
    "predict = tf.argmax(H, axis=1)\n",
    "# # 데이터가 있을 때 열방향한행에서의 최대값이 몇번째ㄱ에 있는가\n",
    "# # 가장 큰값의 index번호를 리턴\n",
    "# # 각각의 예측치에 대한 index번호\n",
    "# # 가장 큰값이 어디에 있는가\n",
    "\n",
    "correct = tf.equal(predict, tf.argmax(Y,axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "print(\"정확도 : {}\".format(sess.run(accuracy,\n",
    "                                feed_dict = {X:test_x_data,\n",
    "                                             Y:test_y_data})))\n",
    "\n",
    "sess.run(H, feed_dict={X : prediction_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 강사님 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-133-77e7f8780375>, line 34)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-133-77e7f8780375>\"\u001b[1;36m, line \u001b[1;32m34\u001b[0m\n\u001b[1;33m    sess.=tf.Session()\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "# Data Loading\n",
    "data_df = pd.read_csv(\"./data/bmi.csv\", skiprows=3)\n",
    "\n",
    "## 결측치와 이상치 처리부터\n",
    "# 결측치 확인\n",
    "data_df.isnull().sum(axis=0)   # 확인한 결과 결측치는 없다\n",
    "# 이상치 확인\n",
    "plt.boxplot(data_df[\"weight\"])   # 확인한 결과 이상치 없음\n",
    "\n",
    "# train, test data set 생성\n",
    "split_num = int(data_df.shape[0] * 0.8)  # 전체 행에 80%\n",
    "scaler = MinMaxScaler()\n",
    "x_data = scarler.fit_transform(data_df[[\"height\"],[\"weight\"]])\n",
    "# 정규화 작업을 진행했다\n",
    "\n",
    "# 학습용, 테스트용, x data을 생성\n",
    "train_x_data = x_data[:split_num]  # 3 numpy 다\n",
    "test_x_data = x_data[split_num:]\n",
    "\n",
    "# 학습용, 테트료 y data를 생성 => one hot incoding\n",
    "# one hot encodeing으로 전환하실때 pandas.get_dumies()\n",
    "#                                  tensorflow.one_hot()\n",
    "tf.one_hot(data_df.loc[:split_num,\"label\"],3 )# 3\n",
    "\n",
    "sess.=tf.Session()\n",
    "sess.run(tf.one_hot(data))\n",
    "sess.run(tf.one_hot(data_df.loc[split_num-1],3))   \n",
    "train_y_data = sess.run(tf.one_hot(data_df_loc[:split_num-1,\"label\"]))\n",
    "test_y_data = sess.run(tf.one_hot(data_df_loc[split_num:,\"label\"]))\n",
    "                                                   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# train_x_data = data_df.loc[:split_num,[\"height\",\"weight\"]]    # data frame\n",
    "# scaler = MinMaxScaler()\n",
    "train_x_data=scaler.fit_transform(train_x_data)  # fit & transform의 두가지 역할\n",
    "# 내가 알아낸 데이터가지고 바꿔라\n",
    "train_x_data\n",
    "scaler.data_max_   # 각각의 열에 대해서 가장 큰값\n",
    "scaler.data_min_\n",
    "# scaler가 train_data set에 대한 최대, 최소값을 가지고 있게 된다.\n",
    "\n",
    "# placeholder\n",
    "X =  tf.placeholder(shape =[None,2], dtype=tf.float32)\n",
    "Y =  tf.placeholder(shape =[None,3], dtype=tf.float32)\n",
    "\n",
    "# Weight, bias\n",
    "W = tf.Variable(tf.random_normal([2,3]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([3]), name=\"bias\")\n",
    "\n",
    "# 실제 구하는 값은 12개\n",
    "\n",
    "# hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "# H = tf.sigmoid  # 각각의 확률이 나와서 한번에 \n",
    "H = tf.nn.softmax(logit) # 이놈이 변경돼!\n",
    "\n",
    "# ocost function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,\n",
    "                                                              labels=Y))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.1).minimize(cost)\n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "# 그래프를 실행하기 위한놈\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# W와 b를 초기화 시키는 것\n",
    "\n",
    "# 학습\n",
    "for step in range(3000):\n",
    "    _,cost_val = sess.run([train,cost], feed_dict={X:train_x_data,\n",
    "                                                   Y:train_y_data})\n",
    "    if step%300==0:\n",
    "        print(\"cost값은:{}\".format(cost_val))\n",
    "        \n",
    "# # Accuracy(정확도)\n",
    "# #predict = tf.cast(H>0.5, dtype=tf.float32)\n",
    "# sess.run(H, feed_dict={X:[[159,50]]})\n",
    "predict = tf.argmax(H, axis=1)\n",
    "# # 데이터가 있을 때 열방향한행에서의 최대값이 몇번째ㄱ에 있는가\n",
    "# # 가장 큰값의 index번호를 리턴\n",
    "# # 각각의 예측치에 대한 index번호\n",
    "# # 가장 큰값이 어디에 있는가\n",
    "\n",
    "correct = tf.equal(predict, tf.argmax(Y,axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "print(\"정확도 : {}\".format(sess.run(accuracy,\n",
    "                                feed_dict = {X:test_x_data,\n",
    "                                             Y:test_y_data})))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-143-e10ade9d4211>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprediction_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m187\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m78\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprediction_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mprediction_data\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "prediction_data = scaler.transform[[187,78]]\n",
    "prediction_data\n",
    "result = sess.run(tf.argmax(H,1), feed_dict={X : prediction_data})[0]\n",
    "\n",
    "if result ==0:\n",
    "    print(\"Thin\")\n",
    "elif result == 1:\n",
    "    print(\"Normal\")\n",
    "else :\n",
    "    print(\"Fat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost값은:2.0564208030700684\n",
      "cost값은:0.7352461218833923\n",
      "cost값은:0.6017679572105408\n",
      "cost값은:0.5322874784469604\n",
      "cost값은:0.48684337735176086\n",
      "cost값은:0.4536226689815521\n",
      "cost값은:0.4277278780937195\n",
      "cost값은:0.406687468290329\n",
      "cost값은:0.3890852630138397\n",
      "cost값은:0.37403595447540283\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt   # 이상치 확인하기 위한 함수\n",
    "import warnings  # 경고 안보이게\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 경고메시지 출력 X\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "# 데이터 불러오기\n",
    "bmi_df = pd.read_csv(\"./data/bmi.csv\", skiprows=3) # 앞의 3줄은 빼고 가져오겠다\n",
    "\n",
    "# # 결측치 확인\n",
    "# bmi_df.isnull().sum()  # 결측치 없음 \n",
    "# # 이상치 확인\n",
    "# plt.boxplot(bmi_df[\"height\"]) # 이상치 없음 \n",
    "# plt.boxplot(bmi_df[\"weight\"]) # 이상치 없음 \n",
    "\n",
    "\n",
    "##################################################################################################\n",
    "\n",
    "# train data와 test data 생성 \n",
    "# 정규화 작업\n",
    "scaler= MinMaxScaler()\n",
    "train_num = int(bmi_df.shape[0]*0.8) \n",
    "# scaler.data_max_  # 가지고있는 데이터의 최대값\n",
    "# scaler.data_min_  # 최대, 최소값 가지고 scaling\n",
    "x_data = scaler.fit_transform(bmi_df[[\"height\",\"weight\"]])\n",
    "\n",
    "# 데이터 분할해 x data 생성 - 80:20\n",
    "train_x_data = x_data[:train_num]  # nparray에서 자른 값 ->  뒤의 값이 exclusive 해서 16000개\n",
    "test_x_data = x_data[train_num:]\n",
    "\n",
    "# 학습용, 테스트용 y data 생성 -> one hot encoding\n",
    "# one hot encoding으로 전환하는 방법 2가지\n",
    "# 1. pandas.get_dummies()\n",
    "# 2. tensorflow.one_hot()\n",
    "sess = tf.Session()\n",
    "train_y_data = sess.run(tf.one_hot(bmi_df.loc[:train_num-1,\"label\"], 3)) # 원래 1차원 자료가 one-hot encoding 적용하면 2차원 자료가 된다.\n",
    "# sess.run(tf.one_hot(bmi_df.loc[:train_num-1,\"label\"], 3)).shape # data frame이라 loc 사용하면 뒤부분 inclusive하다 -> train_num -1 빼줘야 함! \n",
    "test_y_data = sess.run(tf.one_hot(bmi_df.loc[train_num:,\"label\"], 3))\n",
    "\n",
    "#################################################################################################\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,2],dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,3],dtype=tf.float32)\n",
    "\n",
    "# W, b\n",
    "W = tf.Variable(tf.random_normal([2,3]),name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([3]),name=\"bias\")  # 1차원으로 3개\n",
    "\n",
    "# H\n",
    "logit = tf.matmul(X,W)+b \n",
    "H = tf.nn.softmax(logit) \n",
    "\n",
    "# cost function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,   # version2로 해야 정확\n",
    "                                                                labels=Y))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# session\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(3000):\n",
    "    _, cost_val = sess.run([train,cost],feed_dict={X : train_x_data,\n",
    "                                                   Y : train_y_data})\n",
    "    if step%300==0:\n",
    "        print(\"cost값은:{}\".format(cost_val))\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:0.9474999904632568\n"
     ]
    }
   ],
   "source": [
    "# Accuracy(정확도) 측정\n",
    "predict = tf.argmax(H,axis=1)  \n",
    "correct = tf.equal(predict, tf.argmax(Y,axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "print(\"정확도:{}\".format(sess.run(accuracy, feed_dict={X:test_x_data,\n",
    "                                                   Y:test_y_data})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "# prediction_data = [[187,78]]\n",
    "# 예측하기 위해서 다시 scaling한 값 넣어줘야 한다.\n",
    "\n",
    "# MinMax scaler가 min, max값 가지고 있다.\n",
    "prediction_data = scaler.transform([[159,50]])\n",
    "\n",
    "#sess.run(H,feed_dict={X:prediction_data})\n",
    "result = sess.run(tf.argmax(H,1), feed_dict={X:prediction_data})[0]\n",
    "\n",
    "if result ==0:\n",
    "    print(\"Thin\")\n",
    "elif result ==1:\n",
    "    print(\"Normal\")\n",
    "else:\n",
    "    print(\"Fat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[CPU_ENV]",
   "language": "python",
   "name": "cpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
